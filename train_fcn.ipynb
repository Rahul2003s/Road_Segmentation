{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, UpSampling2D, Concatenate\n",
    "from tensorflow.keras.layers import Input, Add, Conv2DTranspose\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, MeanSquaredError, BinaryCrossentropy\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mping\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import  HTML\n",
    "from base64 import b64encode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = \"./dataset/training/image_2/\"\n",
    "train_gt_dir = \"./dataset/training/gt_image_2/\"\n",
    "test_data_dir = \"./dataset/testing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training Examples:  231\n",
      "Number of Validation Examples:  28\n",
      "Number of Testing Examples: 30\n"
     ]
    }
   ],
   "source": [
    "# number of training examples\n",
    "TRAINSET_SIZE = int(len(os.listdir(train_data_dir)) * 0.8)\n",
    "print(\"Number of training Examples: \",TRAINSET_SIZE)\n",
    "\n",
    "VALIDSET_SIZE = int(len(os.listdir(train_data_dir)) * 0.1)\n",
    "print(\"Number of Validation Examples: \",VALIDSET_SIZE)\n",
    "\n",
    "TESTSET_SIZE = int(len(os.listdir(train_data_dir)) - TRAINSET_SIZE - VALIDSET_SIZE)\n",
    "print(f\"Number of Testing Examples: {TESTSET_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Constants\n",
    "IMG_SIZE = 128 #resolution 128 x 128 pixels\n",
    "N_CHANNELS = 3 #RGB\n",
    "N_CLASSES = 1 #no of class to regonize\n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load image and return a dictionary\n",
    "def parse_image(img_path: str) -> dict:\n",
    "    image = tf.io.read_file(img_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=N_CHANNELS)\n",
    "    image = tf.image.convert_image_dtype(image=image,tf.uint8)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7eb90efa10ac2c497c8bcacb4180d38e1cd5214a15a72fd12300310f12ae712"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
